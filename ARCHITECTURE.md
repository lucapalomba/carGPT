# CarGPT Architecture Documentation ğŸ—ï¸

This document describes the architectural structure of the CarGPT backend, which follows the **Model-View-Controller (MVC)** and **Service Layer** patterns.

## ğŸ“ Overview

CarGPT has transitioned from a monolithic `server.js` to a modular architecture to improve maintainability, testability, and scalability. The system is divided into distinct layers with clear responsibilities.

---

## ğŸ“‚ Directory Structure

```text
src/
â”œâ”€â”€ config/             # Application configuration & constants
â”‚   â””â”€â”€ index.js        # Environment variables, Ollama config, session settings
â”œâ”€â”€ controllers/        # Request handlers (Parsing req, calling services, sending res)
â”‚   â”œâ”€â”€ carsController.js    # All car ops: find, refine, ask, alternatives, compare
â”‚   â”œâ”€â”€ healthController.js  # /api/health, /api/reset-conversation
â”‚   â””â”€â”€ qaController.js      # /api/get-conversations (Debug/Admin)
â”œâ”€â”€ middleware/         # Express middleware (Future: validation, auth)
â”œâ”€â”€ models/             # Data structures (Future: Mongoose/Prisma schemas)
â”œâ”€â”€ routes/             # Route definitions
â”‚   â””â”€â”€ api.js          # API route mapping to controllers
â”œâ”€â”€ services/           # Business logic & external integrations
â”‚   â”œâ”€â”€ ollamaService.js       # Ollama API communication & JSON parsing
â”‚   â”œâ”€â”€ conversationService.js # In-memory session management
â”‚   â””â”€â”€ promptService.js       # Prompt template loading
â””â”€â”€ utils/              # Helper functions & validators
```

---

## ğŸ”„ Data Flow

1.  **Request**: The browser sends an HTTP request (e.g., `POST /api/find-cars`) with an `Accept-Language` header.
2.  **Entry Point**: `server.js` receives the request and passes it to the `api.js` router.
3.  **Router**: `api.js` identifies the correct controller method.
4.  **Controller**:
    *   Extracts parameters from `req.body` and headers.
    *   Calls `promptService` to load the appropriate template.
    *   Calls `ollamaService` to interact with the LLM.
    *   Parses the LLM response using `ollamaService.parseJsonResponse`.
    *   Saves the interaction to `conversationService`.
5.  **Response**: The controller sends the processed JSON back to the client.

---

## ğŸ› ï¸ Key Components

### ğŸ§  Ollama Service
Encapsulates all logic for communicating with the local Ollama instance. It handles:
- AI chat requests
- Aggressive JSON cleaning (handling common LLM formatting issues)
- Connectivity health checks

### ğŸ’¬ Conversation Service
Manages in-memory storage for user interactions. Features:
- Session-based isolation
- 1-hour Time-To-Live (TTL) for conversation data
- Automated cleanup background task

### ğŸ“ Prompt Service
Isolates file system operations for loading `.md` prompt templates from the `prompt-templates/` directory.

---

## âœ… Best Practices Implemented

-   **Separation of Concerns**: Business logic is separated from HTTP handling.
-   **Lean Entry Point**: `server.js` is under 100 lines and focuses solely on initialization.
-   **JSDoc Documentation**: All exported functions and methods are documented for better IDE support and developer experience.
-   **Centralized Config**: No hardcoded secrets or environment dependencies outside `src/config/`.
-   **Localization Native**: Built-in support for browser language detection and market restriction across all layers.
